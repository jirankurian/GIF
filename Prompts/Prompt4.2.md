**Your Current Task: Task 4.2 - Implementing the Exoplanet Application Modules (Encoder/Decoder)**

**Protocol Reminder:** Before you begin, you must execute your full **Cognitive Cycle**. Review the `/Rules` directory, the `/Reference/` for Phase 4, read all logs in the `.context/` (including the outcome of Task 4.1), and analyze the current codebase. You will note we have the interfaces for encoders/decoders but no concrete implementations for our exoplanet task. This task will create those first "plug-in" modules. After your analysis, formulate your micro-plan and present it for approval.

---

### **Task Objective**

Your goal is to build the first set of concrete, domain-specific modules for the GIF framework. You will implement the **`LightCurveEncoder`** and the **`ExoplanetDecoder`**. These classes are the first real-world application of the interfaces we designed in Phase 2. They will act as the sensory organ (encoder) and the voice (decoder) for our AI, allowing it to interact with the exoplanet data.

---

### **Domain & Technical Specifications**

#### **1. The "Plug-in" Philosophy in Practice**

* **Domain Context:** Our GIF architecture is designed to be modular. This task is where we prove that concept. The classes you build must strictly adhere to the `EncoderInterface` and `DecoderInterface` contracts. This ensures that the main `GIF` orchestrator can use them without knowing anything about their internal logic, just that they fulfill their contractual obligations (`encode()`, `decode()`, etc.).
* **Technical Approach:** You will create two new Python files, one for each class, in the appropriate subdirectory of the `applications/poc_exoplanet/` package.

#### **2. The `LightCurveEncoder` Implementation**

* **Action:** Create the file `applications/poc_exoplanet/encoders/light_curve_encoder.py`.
* **Class Definition:** Implement a class `LightCurveEncoder` that inherits from `EncoderInterface`.
* **`encode(self, raw_data: polars.DataFrame) -> torch.Tensor`:**
    * **Purpose:** This method's job is to convert a time-series light curve into a pattern of spikes that our SNN can understand.
    * **Input:** It will receive a `polars.DataFrame` (as generated by our `RealisticExoplanetGenerator`) containing "time" and "flux" columns.
    * **Encoding Scheme: Delta Modulation.** This is an efficient and effective scheme for time-series data. The logic is as follows:
        1.  Calculate the difference in flux between consecutive time steps: `delta = flux[t] - flux[t-1]`.
        2.  You will generate a **2-channel spike train**.
        3.  **Channel 1 (Positive Spikes):** If `delta` is positive and exceeds a small sensitivity `threshold`, fire a spike in the first channel.
        4.  **Channel 2 (Negative Spikes):** If `delta` is negative and its absolute value exceeds the `threshold`, fire a spike in the second channel.
        5.  This creates a sparse representation where the SNN is only activated by significant changes in the light curve's brightness, which is computationally efficient.
    * **Return:** A `torch.Tensor` of shape `[num_time_steps, 2]` representing the two-channel spike train.
* **`get_config(self)` and `calibrate(self)`:** Implement these methods to satisfy the interface. `get_config` should return a dictionary of its settings. `calibrate` can simply contain `pass` for now.

#### **3. The `ExoplanetDecoder` Implementation**

* **Action:** Create the file `applications/poc_exoplanet/decoders/exoplanet_decoder.py`.
* **Class Definition:** Implement a class `ExoplanetDecoder` that inherits from `DecoderInterface`. This class will be a `torch.nn.Module` itself because its regression mode will contain trainable parameters.
* **Domain Context:** The decoder's job is to interpret the pattern of output spikes from the DU Core. The SNN does the complex temporal analysis; the decoder translates its final "thought" into a concrete answer.
* **`decode(self, spike_train: torch.Tensor, mode: str = 'classification') -> Any`:**
    * **Purpose:** This method will perform the final translation from spikes to answer. It will support two modes, as required by our research paper's validation plan.
    * **`mode='classification'`:**
        1.  **Readout Logic: Population Coding.** Count the total number of spikes for each output neuron across the entire simulation time window.
        2.  The index of the neuron with the highest spike count corresponds to the predicted class label (e.g., index 0 = "Not Planet", index 1 = "Planet").
        3.  Return the predicted class index or label.
    * **`mode='regression'`:**
        1.  **Purpose:** This mode is for the "Advanced Feature Prediction" task.
        2.  **Readout Logic:** First, sum the spikes for each output neuron as in classification to get a vector of spike counts.
        3.  Pass this vector through a simple `torch.nn.Linear` layer that you define in the decoder's `__init__` method. This linear layer will map the spike counts to one or more continuous physical values (e.g., a single value for the planet's radius).
        4.  Return the resulting regression value(s).

---

**Summary of your task:**

1.  Create the file `applications/poc_exoplanet/encoders/light_curve_encoder.py` and implement the `LightCurveEncoder` class, ensuring it inherits from the correct interface and uses Delta Modulation for its encoding logic.
2.  Create the file `applications/poc_exoplanet/decoders/exoplanet_decoder.py` and implement the `ExoplanetDecoder` class, ensuring it inherits from the interface and contains logic for both `classification` and `regression` modes.
3.  Ensure both classes are professionally documented with clear docstrings explaining their specific role in the exoplanet POC.

Now, following your protocol, please formulate your micro-plan for this task.

**Awaiting approval to proceed.**